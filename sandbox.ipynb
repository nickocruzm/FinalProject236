{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0fc5f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/10/07 18:46:19 WARN Utils: Your hostname, Nickos-Mac.local resolves to a loopback address: 127.0.0.1; using 2600:6c88:9b40:54:0:0:0:12f2 instead (on interface en0)\n",
      "25/10/07 18:46:19 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/10/07 18:46:19 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading datasets...\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "import pyspark.sql.functions as F\n",
    "import os\n",
    "\n",
    "# Initialize Spark Session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Hotel Bookings EDA\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"8\") \\\n",
    "    .config(\"spark.driver.host\", \"localhost\") \\\n",
    "    .config(\"spark.ui.enabled\", \"false\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "\n",
    "print(\"\\nLoading datasets...\")\n",
    "\n",
    "# Load the two CSV files\n",
    "df1 = spark.read.csv(\"hotel-booking.csv\", header=True, inferSchema=True)\n",
    "df2 = spark.read.csv(\"customer-reservations.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef6f0d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hotel Booking loaded: 78703 rows\n",
      "Customer Reservations loaded: 36275 rows\n",
      "\n",
      "--- Hotel Booking Schema ---\n",
      "root\n",
      " |-- hotel: string (nullable = true)\n",
      " |-- booking_status: integer (nullable = true)\n",
      " |-- lead_time: integer (nullable = true)\n",
      " |-- arrival_year: integer (nullable = true)\n",
      " |-- arrival_month: string (nullable = true)\n",
      " |-- arrival_date_week_number: integer (nullable = true)\n",
      " |-- arrival_date_day_of_month: integer (nullable = true)\n",
      " |-- stays_in_weekend_nights: integer (nullable = true)\n",
      " |-- stays_in_week_nights: integer (nullable = true)\n",
      " |-- market_segment_type: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- avg_price_per_room: double (nullable = true)\n",
      " |-- email: string (nullable = true)\n",
      "\n",
      "\n",
      "--- Customer Reservations Schema ---\n",
      "root\n",
      " |-- Booking_ID: string (nullable = true)\n",
      " |-- stays_in_weekend_nights: integer (nullable = true)\n",
      " |-- stays_in_week_nights: integer (nullable = true)\n",
      " |-- lead_time: integer (nullable = true)\n",
      " |-- arrival_year: integer (nullable = true)\n",
      " |-- arrival_month: integer (nullable = true)\n",
      " |-- arrival_date: integer (nullable = true)\n",
      " |-- market_segment_type: string (nullable = true)\n",
      " |-- avg_price_per_room: double (nullable = true)\n",
      " |-- booking_status: string (nullable = true)\n",
      "\n",
      "\n",
      "--- Column Comparison ---\n",
      "Hotel Booking has 13 columns\n",
      "Customer Reservations has 10 columns\n",
      "Overlapping columns: 8\n",
      "\n",
      "Unique to Hotel Booking (5 columns):\n",
      "  - arrival_date_day_of_month\n",
      "  - arrival_date_week_number\n",
      "  - country\n",
      "  - email\n",
      "  - hotel\n",
      "\n",
      "Unique to Customer Reservations (2 columns):\n",
      "  - Booking_ID\n",
      "  - arrival_date\n"
     ]
    }
   ],
   "source": [
    "print(f\"Hotel Booking loaded: {df1.count()} rows\")\n",
    "print(f\"Customer Reservations loaded: {df2.count()} rows\")\n",
    "print(\"\\n--- Hotel Booking Schema ---\")\n",
    "df1.printSchema()\n",
    "print(\"\\n--- Customer Reservations Schema ---\")\n",
    "df2.printSchema()\n",
    "# Compare column names\n",
    "cols1 = set(df1.columns)\n",
    "cols2 = set(df2.columns)\n",
    "\n",
    "print(\"\\n--- Column Comparison ---\")\n",
    "print(f\"Hotel Booking has {len(cols1)} columns\")\n",
    "print(f\"Customer Reservations has {len(cols2)} columns\")\n",
    "print(f\"Overlapping columns: {len(cols1.intersection(cols2))}\")\n",
    "# FIND UNIQUE COLUMNS\n",
    "unique_to_1 = cols1 - cols2\n",
    "unique_to_2 = cols2 - cols1\n",
    "\n",
    "if unique_to_1:\n",
    "    print(f\"\\nUnique to Hotel Booking ({len(unique_to_1)} columns):\")\n",
    "    for column in sorted(unique_to_1):\n",
    "        print(f\"  - {column}\")\n",
    "\n",
    "if unique_to_2:\n",
    "    print(f\"\\nUnique to Customer Reservations ({len(unique_to_2)} columns):\")\n",
    "    for column in sorted(unique_to_2):\n",
    "        print(f\"  - {column}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8a310f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Null Value Analysis...\n",
      "\n",
      "--- Hotel Booking Null Analysis ---\n",
      "Columns with null values: 1/13\n",
      "\n",
      "Column                           Null Count   Percentage\n",
      "--------------------------------------------------------\n",
      "country                                 405        0.51%\n",
      "\n",
      "--- Customer Reservations Null Analysis ---\n",
      "No null values found!\n"
     ]
    }
   ],
   "source": [
    "# NULL VALUE ANALYSIS\n",
    "print(\"\\nNull Value Analysis...\")\n",
    "\n",
    "def analyze_nulls(df, name):\n",
    "    \"\"\"Analyze null values in the dataset\"\"\"\n",
    "    print(f\"\\n--- {name} Null Analysis ---\")\n",
    "    \n",
    "    # Calculate null counts for all columns\n",
    "    null_counts = []\n",
    "    for c in df.columns:\n",
    "        null_count = df.filter(col(c).isNull()).count()\n",
    "        null_counts.append((c, null_count))\n",
    "    \n",
    "    # Filter and sort columns with nulls\n",
    "    columns_with_nulls = [(c, n) for c, n in null_counts if n > 0]\n",
    "    columns_with_nulls.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    total_rows = df.count()\n",
    "    \n",
    "    if columns_with_nulls:\n",
    "        print(f\"Columns with null values: {len(columns_with_nulls)}/{len(df.columns)}\")\n",
    "        print(f\"\\n{'Column':<30} {'Null Count':>12} {'Percentage':>12}\")\n",
    "        print(\"-\" * 56)\n",
    "        for col_name, null_count in columns_with_nulls:\n",
    "            pct = (null_count / total_rows) * 100\n",
    "            print(f\"{col_name:<30} {null_count:>12,} {pct:>11.2f}%\")\n",
    "    else:\n",
    "        print(\"No null values found!\")\n",
    "\n",
    "analyze_nulls(df1, \"Hotel Booking\")\n",
    "analyze_nulls(df2, \"Customer Reservations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f07f855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distinct Value Analysis...\n",
      "\n",
      "--- Hotel Booking Distinct Values ---\n",
      "\n",
      "Column                            Distinct Values    Uniqueness %\n",
      "-----------------------------------------------------------------\n",
      "hotel                                           2           0.00%\n",
      "booking_status                                  2           0.00%\n",
      "lead_time                                     439           0.56%\n",
      "arrival_year                                    2           0.00%\n",
      "arrival_month                                  12           0.02%\n",
      "arrival_date_week_number                       53           0.07%\n",
      "arrival_date_day_of_month                      31           0.04%\n",
      "stays_in_weekend_nights                        17           0.02%\n",
      "stays_in_week_nights                           32           0.04%\n",
      "market_segment_type                             8           0.01%\n",
      "country                                       160           0.20%\n",
      "avg_price_per_room                          6,985           8.88%\n",
      "email                                      77,144          98.02%\n",
      "\n",
      "--- Customer Reservations Distinct Values ---\n",
      "\n",
      "Column                            Distinct Values    Uniqueness %\n",
      "-----------------------------------------------------------------\n",
      "Booking_ID                                 36,275         100.00%\n",
      "stays_in_weekend_nights                         8           0.02%\n",
      "stays_in_week_nights                           18           0.05%\n",
      "lead_time                                     352           0.97%\n",
      "arrival_year                                    2           0.01%\n",
      "arrival_month                                  12           0.03%\n",
      "arrival_date                                   31           0.09%\n",
      "market_segment_type                             5           0.01%\n",
      "avg_price_per_room                          3,930          10.83%\n",
      "booking_status                                  2           0.01%\n"
     ]
    }
   ],
   "source": [
    "# DISTINCT VALUE ANALYSIS\n",
    "print(\"\\nDistinct Value Analysis...\")\n",
    "\n",
    "def analyze_distinct_values(df, name):\n",
    "    \"\"\"Analyze distinct values for all columns\"\"\"\n",
    "    print(f\"\\n--- {name} Distinct Values ---\")\n",
    "    print(f\"\\n{'Column':<30} {'Distinct Values':>18} {'Uniqueness %':>15}\")\n",
    "    print(\"-\" * 65)\n",
    "    \n",
    "    total_rows = df.count()\n",
    "    \n",
    "    for c in df.columns:\n",
    "        distinct_count = df.select(c).distinct().count()\n",
    "        uniqueness = (distinct_count / total_rows) * 100\n",
    "        print(f\"{c:<30} {distinct_count:>18,} {uniqueness:>14.2f}%\")\n",
    "\n",
    "analyze_distinct_values(df1, \"Hotel Booking\")\n",
    "analyze_distinct_values(df2, \"Customer Reservations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b7d1ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data Type Analysis...\n",
      "\n",
      "--- Hotel Bookings Data Types ---\n",
      "\n",
      "Data Type                 Count\n",
      "--------------------------------\n",
      "int                           7\n",
      "string                        5\n",
      "double                        1\n",
      "\n",
      "--- Customer Reservations Data Types ---\n",
      "\n",
      "Data Type                 Count\n",
      "--------------------------------\n",
      "int                           6\n",
      "string                        3\n",
      "double                        1\n"
     ]
    }
   ],
   "source": [
    "# DATA TYPE ANALYSIS\n",
    "print(\"\\nData Type Analysis...\")\n",
    "\n",
    "def analyze_data_types(df, name):\n",
    "    \"\"\"Show data types distribution\"\"\"\n",
    "    print(f\"\\n--- {name} Data Types ---\")\n",
    "    \n",
    "    type_counts = {}\n",
    "    for col_name, col_type in df.dtypes:\n",
    "        type_counts[col_type] = type_counts.get(col_type, 0) + 1\n",
    "    \n",
    "    print(f\"\\n{'Data Type':<20} {'Count':>10}\")\n",
    "    print(\"-\" * 32)\n",
    "    for dtype, count in sorted(type_counts.items(), key=lambda x: x[1], reverse=True):\n",
    "        print(f\"{dtype:<20} {count:>10}\")\n",
    "\n",
    "analyze_data_types(df1, \"Hotel Bookings\")\n",
    "analyze_data_types(df2, \"Customer Reservations\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbab64c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking for Data Type Mismatches...\n",
      "\n",
      "Comparing 8 common columns...\n",
      "\n",
      "Found 2 type mismatches:\n",
      "\n",
      "Column                         Hotel Bookings Type  Customer Reservations Type\n",
      "------------------------------------------------------------------------\n",
      "arrival_month                  string               int                 \n",
      "booking_status                 int                  string              \n"
     ]
    }
   ],
   "source": [
    "# DATA TYPE MISMATCHES\n",
    "print(\"\\nChecking for Data Type Mismatches...\")\n",
    "\n",
    "def compare_column_types(df1, df2):\n",
    "    \"\"\"Compare data types of common columns\"\"\"\n",
    "    common_cols = sorted(set(df1.columns).intersection(set(df2.columns)))\n",
    "        \n",
    "    df1_types = dict(df1.dtypes)\n",
    "    df2_types = dict(df2.dtypes)\n",
    "    \n",
    "    mismatches = []\n",
    "    matches = []\n",
    "    \n",
    "    for col_name in common_cols:\n",
    "        type1 = df1_types[col_name]\n",
    "        type2 = df2_types[col_name]\n",
    "        \n",
    "        if type1 != type2:\n",
    "            mismatches.append((col_name, type1, type2))\n",
    "        else:\n",
    "            matches.append(col_name)\n",
    "    return mismatches\n",
    "\n",
    "common_cols = sorted(set(df1.columns).intersection(set(df2.columns)))\n",
    "\n",
    "print(f\"\\nComparing {len(common_cols)} common columns...\")\n",
    "type_mismatches = compare_column_types(df1, df2)\n",
    "\n",
    "if type_mismatches:\n",
    "    print(f\"\\nFound {len(type_mismatches)} type mismatches:\")\n",
    "    print(f\"\\n{'Column':<30} {'Hotel Bookings Type':<20} {'Customer Reservations Type':<20}\")\n",
    "    print(\"-\" * 72)\n",
    "    \n",
    "    for col_name, type1, type2 in type_mismatches:\n",
    "        print(f\"{col_name:<30} {type1:<20} {type2:<20}\")\n",
    "else:\n",
    "    print(\"\\nAll common columns have matching types!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0c9ae3",
   "metadata": {},
   "source": [
    "## 1.3 Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed9e722",
   "metadata": {},
   "source": [
    "Matching datatypes for overlapping columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a08824e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Types all match. 0 mismatches\n"
     ]
    }
   ],
   "source": [
    "# Standardize column types\n",
    "for col_name, type1, type2 in compare_column_types(df1, df2):\n",
    "    # Cast df2’s column to df1’s type (or vice versa)\n",
    "    df2 = df2.withColumn(col_name, df2[col_name].cast(type1))\n",
    "\n",
    "mismatches = compare_column_types(df1,df2)\n",
    "\n",
    "if mismatches:\n",
    "    print(f' mismatches: {len(mismatches)}')\n",
    "else:\n",
    "    print(f'Types all match. {len(mismatches)} mismatches')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99956748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "10\n",
      "23\n"
     ]
    }
   ],
   "source": [
    "print(f'{len(df1.columns)}')\n",
    "print(f'{len(df2.columns)}')\n",
    "\n",
    "print(len(df1.columns) + len(df2.columns))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50229db5",
   "metadata": {},
   "source": [
    "Renaming overlapping columns, to avoid collisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ff2b93ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['arrival_month', 'arrival_year', 'avg_price_per_room', 'booking_status', 'lead_time', 'market_segment_type', 'stays_in_week_nights', 'stays_in_weekend_nights']\n"
     ]
    }
   ],
   "source": [
    "overlapping_columns = sorted(set(df1.columns).intersection(set(df2.columns)))\n",
    "print(overlapping_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "79ad126e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "hotel_columns = df1.columns\n",
    "customer_columns = df2.columns\n",
    "\n",
    "for c in overlapping_columns:\n",
    "    df1 = df1.withColumnRenamed(c, \"hotel_\"+c)\n",
    "    df2 = df2.withColumnRenamed(c, \"customer\"+c)\n",
    "\n",
    "overlapping_columns = sorted(set(df1.columns).intersection(set(df2.columns)))\n",
    "print(overlapping_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b63021dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def union_fill_na(df1, df2):\n",
    "    # Get all columns\n",
    "    all_cols = set(df1.columns) | set(df2.columns)\n",
    "    \n",
    "    # Add missing columns to each DataFrame\n",
    "    for col in all_cols - set(df1.columns):\n",
    "        df1 = df1.withColumn(col, F.lit(None))\n",
    "    for col in all_cols - set(df2.columns):\n",
    "        df2 = df2.withColumn(col, F.lit(None))\n",
    "    \n",
    "    # Reorder columns to match\n",
    "    df1 = df1.select(*all_cols)\n",
    "    df2 = df2.select(*all_cols)\n",
    "    \n",
    "    return df1.unionByName(df2)\n",
    "\n",
    "merged_df = union_fill_na(df1, df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f62016a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[customerbooking_status: int, customerarrival_month: string, hotel: string, customerstays_in_weekend_nights: int, hotel_arrival_year: int, arrival_date_day_of_month: int, customerlead_time: int, customerstays_in_week_nights: int, arrival_date_week_number: int, hotel_market_segment_type: string, hotel_booking_status: int, hotel_avg_price_per_room: double, customerarrival_year: int, hotel_stays_in_weekend_nights: int, hotel_lead_time: int, hotel_stays_in_week_nights: int, email: string, Booking_ID: string, hotel_arrival_month: string, country: string, arrival_date: int, customermarket_segment_type: string, customeravg_price_per_room: double]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7b9d3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
